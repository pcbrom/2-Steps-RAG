{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    model  attempt  temperature  top_p     rag_type  \\\n",
      "0  gpt-4o-mini-2024-07-18        1          0.1    0.1  2-steps RAG   \n",
      "1  gpt-4o-mini-2024-07-18        1          0.1    0.5  2-steps RAG   \n",
      "2  gpt-4o-mini-2024-07-18        1          0.1    0.9  2-steps RAG   \n",
      "3  gpt-4o-mini-2024-07-18        1          1.0    0.1  2-steps RAG   \n",
      "4  gpt-4o-mini-2024-07-18        1          1.0    0.5  2-steps RAG   \n",
      "\n",
      "                                              prompt  \\\n",
      "0  Qual a descrição oficial do código NCM para a ...   \n",
      "1  Qual a descrição oficial do código NCM para a ...   \n",
      "2  Qual a descrição oficial do código NCM para a ...   \n",
      "3  Qual a descrição oficial do código NCM para a ...   \n",
      "4  Qual a descrição oficial do código NCM para a ...   \n",
      "\n",
      "                                    augmented_prompt  \\\n",
      "0  \\n    Você é um assistente especializado em re...   \n",
      "1  \\n    Você é um assistente especializado em re...   \n",
      "2  \\n    Você é um assistente especializado em re...   \n",
      "3  \\n    Você é um assistente especializado em re...   \n",
      "4  \\n    Você é um assistente especializado em re...   \n",
      "\n",
      "                                            baseline  \\\n",
      "0  A descrição correta de acordo com a Nomenclatu...   \n",
      "1  A descrição correta de acordo com a Nomenclatu...   \n",
      "2  A descrição correta de acordo com a Nomenclatu...   \n",
      "3  A descrição correta de acordo com a Nomenclatu...   \n",
      "4  A descrição correta de acordo com a Nomenclatu...   \n",
      "\n",
      "                                             results  \n",
      "0  A descrição oficial do código NCM para a merca...  \n",
      "1  A descrição oficial do código NCM para a merca...  \n",
      "2  A descrição oficial do código NCM para a merca...  \n",
      "3  A descrição oficial do código NCM para a merca...  \n",
      "4  A descrição oficial do código NCM para a merca...  \n",
      "rag_type\n",
      "2-steps RAG    9016\n",
      "Common RAG     9016\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the paths to the directories containing the CSV files\n",
    "dir_2_steps_rag = \"results 2-steps RAG\"\n",
    "dir_common_rag = \"results Common RAG\"\n",
    "\n",
    "# Function to read CSV files from a directory and add a 'rag_type' column\n",
    "def read_and_label_csvs(directory, rag_type):\n",
    "    dfs = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            try:\n",
    "                df = pd.read_csv(filepath, encoding='utf-8')\n",
    "                df['rag_type'] = rag_type\n",
    "                columns_to_remove = ['score', 'prompt_tokens', 'augmented_prompt_tokens', 'results_tokens', 'prompt_cost', 'results_cost', 'total_cost']\n",
    "                df = df.drop(columns=[col for col in columns_to_remove if col in df.columns])\n",
    "                dfs.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "    return dfs\n",
    "\n",
    "# Read and label CSV files from both directories\n",
    "dfs_2_steps = read_and_label_csvs(dir_2_steps_rag, \"2-steps RAG\")\n",
    "dfs_common = read_and_label_csvs(dir_common_rag, \"Common RAG\")\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "all_dfs = dfs_2_steps + dfs_common\n",
    "\n",
    "if all_dfs:\n",
    "    final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "    \n",
    "    # Reorder columns\n",
    "    desired_order = ['model', 'attempt', 'temperature', 'top_p', 'rag_type', 'prompt', 'augmented_prompt', 'baseline', 'results']\n",
    "    existing_columns = [col for col in desired_order if col in final_df.columns]\n",
    "    final_df = final_df[existing_columns]\n",
    "\n",
    "    print(final_df.head())\n",
    "    print(final_df.rag_type.value_counts())\n",
    "else:\n",
    "    print(\"No CSV files found in the specified directories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            model  attempt  temperature  top_p     rag_type  \\\n",
      "0          gpt-4o-mini-2024-07-18        1          0.1    0.1  2-steps RAG   \n",
      "1          gpt-4o-mini-2024-07-18        1          0.1    0.5  2-steps RAG   \n",
      "2          gpt-4o-mini-2024-07-18        1          0.1    0.9  2-steps RAG   \n",
      "3          gpt-4o-mini-2024-07-18        1          1.0    0.1  2-steps RAG   \n",
      "4          gpt-4o-mini-2024-07-18        1          1.0    0.5  2-steps RAG   \n",
      "...                           ...      ...          ...    ...          ...   \n",
      "18027  TeenyTinyLlama-160m-NCM-ft      196          1.0    0.5   Common RAG   \n",
      "18028  TeenyTinyLlama-160m-NCM-ft      196          1.0    0.9   Common RAG   \n",
      "18029  TeenyTinyLlama-160m-NCM-ft      196          1.9    0.1   Common RAG   \n",
      "18030  TeenyTinyLlama-160m-NCM-ft      196          1.9    0.5   Common RAG   \n",
      "18031  TeenyTinyLlama-160m-NCM-ft      196          1.9    0.9   Common RAG   \n",
      "\n",
      "                                                baseline  \\\n",
      "0      A descrição correta de acordo com a Nomenclatu...   \n",
      "1      A descrição correta de acordo com a Nomenclatu...   \n",
      "2      A descrição correta de acordo com a Nomenclatu...   \n",
      "3      A descrição correta de acordo com a Nomenclatu...   \n",
      "4      A descrição correta de acordo com a Nomenclatu...   \n",
      "...                                                  ...   \n",
      "18027  A descrição correta de acordo com a Nomenclatu...   \n",
      "18028  A descrição correta de acordo com a Nomenclatu...   \n",
      "18029  A descrição correta de acordo com a Nomenclatu...   \n",
      "18030  A descrição correta de acordo com a Nomenclatu...   \n",
      "18031  A descrição correta de acordo com a Nomenclatu...   \n",
      "\n",
      "                                                 results  \n",
      "0      A descrição oficial do código NCM para a merca...  \n",
      "1      A descrição oficial do código NCM para a merca...  \n",
      "2      A descrição oficial do código NCM para a merca...  \n",
      "3      A descrição oficial do código NCM para a merca...  \n",
      "4      A descrição oficial do código NCM para a merca...  \n",
      "...                                                  ...  \n",
      "18027                                                ...  \n",
      "18028      Não insira outras informações além do códi...  \n",
      "18029                                                ...  \n",
      "18030    Em outras palavras, se as informações fornec...  \n",
      "18031   Resposta aberta:\\n\\n      A empresa informa s...  \n",
      "\n",
      "[18032 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df = final_df[['model', 'attempt', 'temperature', 'top_p', 'rag_type', 'baseline', 'results']]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Specify the path to your .env file\n",
    "dotenv_path = \"/mnt/4d4f90e5-f220-481e-8701-f0a546491c35/arquivos/projetos/.env\"\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "# Access and store the environment variable\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model = 'gpt-4o-mini-2024-07-18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'comparison_prompt'] = final_df.apply(lambda row: f\"\"\"Avalie as respostas abaixo de 0 a 10, em que 0 representa discordância total e 10 concordância total, considerando os seguintes critérios:\n",
    "\n",
    "        *Qualidade da Resposta*: A resposta é clara, concisa e bem estruturada ao responder quando comparada ao baseline?\n",
    "        *Concordância*: A resposta faz sentido no contexto comparativo com o baseline?\n",
    "        *Precisão/Acurácia*: A resposta apresenta informações corretas ao serem comparadas com o baseline?\n",
    "        **Alucinação**: A resposta contém informações inventadas ou inconsistentes com a pergunta ou baseline, ou afirmações sem embasamento verificável? Penalize a nota se o conteúdo parecer falso ou fabricado.\n",
    "\n",
    "        Resposta Base (Baseline): {row['baseline']}\n",
    "        Resposta do Modelo: {row['results']}\n",
    "\n",
    "        Atribua uma nota de 0 a 10 para a comparação entre as respostas (Baseline e Modelo), justificando brevemente sua avaliação. \n",
    "        Respostas do modelo que indicam falta de acesso a informações específicas e recomendam consultar fontes externas (ex: \"Desculpe, mas não tenho acesso a informações específicas como CEPs...\") devem ser penalizadas, pois não atingiram o objetivo.\n",
    "        Retorne a avaliação no formato JSON, com as chaves \"quality\", \"agreement\", \"accuracy\", \"hallucination\" e \"justification\". \n",
    "        Não penalize a avaliação em caso de repetições no texto.\n",
    "\"\"\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avalie as respostas abaixo de 0 a 10, em que 0 representa discordância total e 10 concordância total, considerando os seguintes critérios:\n",
      "\n",
      "        *Qualidade da Resposta*: A resposta é clara, concisa e bem estruturada ao responder quando comparada ao baseline?\n",
      "        *Concordância*: A resposta faz sentido no contexto comparativo com o baseline?\n",
      "        *Precisão/Acurácia*: A resposta apresenta informações corretas ao serem comparadas com o baseline?\n",
      "        **Alucinação**: A resposta contém informações inventadas ou inconsistentes com a pergunta ou baseline, ou afirmações sem embasamento verificável? Penalize a nota se o conteúdo parecer falso ou fabricado.\n",
      "\n",
      "        Resposta Base (Baseline): A descrição correta de acordo com a Nomenclatura Comum do Mercusul para 'VASSOURAO CERPA PLAST FIO RIGIDO 370X63MM MAX' é Vassouras e escovas, mesmo constituindo partes de máquinas, de aparelhos ou de veículos, vassouras mecânicas de uso manual não motorizadas, pincéis e espanadores; cabeças preparadas para escovas, pincéis e artigos semelhantes; bonecas e rolos para pintura   - Outros\n",
      "        Resposta do Modelo: A descrição oficial do código NCM para a mercadoria \"VASSOURAO CERPA PLAST FIO RIGIDO 370X63MM MAX\" é 96039000, que se refere a \"vassouras, rodos, cabos e afins\".\n",
      "\n",
      "        Atribua uma nota de 0 a 10 para a comparação entre as respostas (Baseline e Modelo), justificando brevemente sua avaliação. \n",
      "        Respostas do modelo que indicam falta de acesso a informações específicas e recomendam consultar fontes externas (ex: \"Desculpe, mas não tenho acesso a informações específicas como CEPs...\") devem ser penalizadas, pois não atingiram o objetivo.\n",
      "        Retorne a avaliação no formato JSON, com as chaves \"quality\", \"agreement\", \"accuracy\", \"hallucination\" e \"justification\". \n",
      "        Não penalize a avaliação em caso de repetições no texto.\n",
      "\n",
      "18032\n"
     ]
    }
   ],
   "source": [
    "print(df['comparison_prompt'][0])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   1%|          | 150/18032 [07:11<13:50:22,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 300/18032 [14:34<12:20:46,  2.51s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   2%|▏         | 450/18032 [22:45<11:36:59,  2.38s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 600/18032 [31:09<13:42:40,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   4%|▍         | 750/18032 [38:25<12:55:32,  2.69s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   5%|▍         | 900/18032 [46:38<14:10:04,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   6%|▌         | 1050/18032 [54:34<12:45:26,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   7%|▋         | 1200/18032 [1:02:22<11:33:52,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   7%|▋         | 1350/18032 [1:09:28<9:14:20,  1.99s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   8%|▊         | 1500/18032 [1:17:04<12:39:22,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   9%|▉         | 1650/18032 [1:25:02<11:02:31,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  10%|▉         | 1800/18032 [1:33:11<12:12:56,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  11%|█         | 1950/18032 [1:41:34<11:06:44,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  12%|█▏        | 2100/18032 [1:49:32<12:15:33,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  12%|█▏        | 2250/18032 [1:57:50<13:00:17,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  13%|█▎        | 2400/18032 [2:05:26<10:28:04,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  14%|█▍        | 2550/18032 [2:13:48<12:25:06,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  15%|█▍        | 2700/18032 [2:21:41<11:39:39,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  16%|█▌        | 2850/18032 [2:29:25<9:36:13,  2.28s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  17%|█▋        | 3000/18032 [2:37:32<12:16:13,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  17%|█▋        | 3150/18032 [2:44:42<10:19:14,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  18%|█▊        | 3300/18032 [2:51:25<7:04:36,  1.73s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  19%|█▉        | 3450/18032 [2:59:01<9:28:20,  2.34s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  20%|█▉        | 3600/18032 [3:06:32<15:09:13,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  21%|██        | 3750/18032 [3:14:46<11:49:04,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  22%|██▏       | 3900/18032 [3:21:59<8:21:07,  2.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  22%|██▏       | 4050/18032 [3:28:44<12:09:19,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  23%|██▎       | 4200/18032 [3:37:04<10:07:27,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  24%|██▍       | 4350/18032 [3:44:52<12:04:58,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  25%|██▍       | 4500/18032 [3:52:11<8:29:01,  2.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  26%|██▌       | 4650/18032 [4:00:31<9:28:59,  2.55s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  27%|██▋       | 4800/18032 [4:08:29<11:14:18,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  27%|██▋       | 4950/18032 [4:16:00<13:09:49,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  28%|██▊       | 5100/18032 [4:23:43<7:25:35,  2.07s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  29%|██▉       | 5250/18032 [4:31:39<10:42:13,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  30%|██▉       | 5400/18032 [4:39:44<13:57:04,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  31%|███       | 5550/18032 [4:48:45<8:35:01,  2.48s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  32%|███▏      | 5700/18032 [4:56:33<7:35:34,  2.22s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  32%|███▏      | 5850/18032 [5:04:01<7:32:42,  2.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  33%|███▎      | 6000/18032 [5:12:23<9:41:35,  2.90s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  34%|███▍      | 6150/18032 [5:20:46<7:04:01,  2.14s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  35%|███▍      | 6300/18032 [5:28:37<7:38:38,  2.35s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  36%|███▌      | 6450/18032 [5:35:47<7:57:21,  2.47s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  37%|███▋      | 6600/18032 [5:43:00<8:07:37,  2.56s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  37%|███▋      | 6750/18032 [5:49:54<10:55:31,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  38%|███▊      | 6900/18032 [5:57:03<6:55:11,  2.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  39%|███▉      | 7050/18032 [6:05:16<8:06:34,  2.66s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  40%|███▉      | 7200/18032 [6:14:23<7:38:49,  2.54s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  41%|████      | 7350/18032 [6:23:54<8:00:05,  2.70s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  42%|████▏     | 7500/18032 [6:32:06<7:46:40,  2.66s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  42%|████▏     | 7523/18032 [6:34:12<9:26:42,  3.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para fornecer uma avaliação adequada, preciso que você me forneça a \"Resposta do Modelo\" que deseja que eu avalie em comparação com a \"Resposta Base\". Por favor, compartilhe essa informação para que eu possa proceder com a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  42%|████▏     | 7649/18032 [6:40:22<4:54:42,  1.70s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para fornecer uma avaliação adequada, preciso que você me forneça a \"Resposta do Modelo\" que deseja que eu avalie em comparação com a \"Resposta Base\". Por favor, compartilhe essa informação para que eu possa proceder com a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  42%|████▏     | 7650/18032 [6:40:26<6:56:14,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  42%|████▏     | 7651/18032 [6:41:27<58:02:44, 20.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para fornecer uma avaliação adequada, preciso que você me forneça a \"Resposta do Modelo\" que deseja que eu avalie em comparação com a \"Resposta Base\". Por favor, compartilhe essa informação para que eu possa proceder com a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  42%|████▏     | 7652/18032 [6:41:28<41:24:30, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para fornecer uma avaliação adequada, preciso que você me forneça a \"Resposta do Modelo\" que deseja que eu avalie em comparação com a \"Resposta Base\". Por favor, compartilhe essa informação para que eu possa prosseguir com a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  42%|████▏     | 7655/18032 [6:41:34<17:44:50,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para fornecer uma avaliação adequada, preciso que você me forneça a \"Resposta do Modelo\" que deseja que eu avalie em comparação com a \"Resposta Base\". Por favor, compartilhe essa informação para que eu possa proceder com a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  43%|████▎     | 7800/18032 [6:48:23<7:25:43,  2.61s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  44%|████▍     | 7950/18032 [6:55:22<5:22:06,  1.92s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  45%|████▍     | 8100/18032 [7:02:08<5:01:11,  1.82s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  46%|████▌     | 8250/18032 [7:09:54<5:27:55,  2.01s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  47%|████▋     | 8400/18032 [7:16:34<5:00:43,  1.87s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  47%|████▋     | 8550/18032 [7:23:01<5:44:16,  2.18s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  48%|████▊     | 8700/18032 [7:30:34<6:11:29,  2.39s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  48%|████▊     | 8712/18032 [7:32:03<5:48:48,  2.25s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para realizar a avaliação, precisamos de uma resposta do modelo para comparar com a resposta base. Como você não forneceu uma resposta do modelo, não posso atribuir notas ou justificar a avaliação. Por favor, forneça a resposta do modelo para que eu possa proceder com a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  48%|████▊     | 8717/18032 [7:32:21<7:00:17,  2.71s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para realizar a avaliação, precisamos de uma resposta do modelo para comparar com a resposta base. Como você não forneceu uma resposta do modelo, não posso atribuir notas ou justificar a avaliação. Por favor, forneça a resposta do modelo para que eu possa proceder com a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  49%|████▉     | 8850/18032 [7:38:21<6:27:33,  2.53s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  50%|████▉     | 9000/18032 [7:45:49<6:06:43,  2.44s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  51%|█████     | 9150/18032 [7:53:04<5:52:28,  2.38s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  52%|█████▏    | 9300/18032 [8:01:54<7:15:06,  2.99s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  52%|█████▏    | 9450/18032 [8:10:21<5:09:02,  2.16s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  53%|█████▎    | 9600/18032 [8:17:39<5:44:34,  2.45s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  54%|█████▍    | 9750/18032 [8:24:51<6:31:42,  2.84s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  55%|█████▍    | 9900/18032 [8:31:54<4:16:01,  1.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  56%|█████▌    | 10050/18032 [8:38:46<4:46:29,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  57%|█████▋    | 10200/18032 [8:45:27<5:01:31,  2.31s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  57%|█████▋    | 10350/18032 [8:53:17<6:35:41,  3.09s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  58%|█████▊    | 10500/18032 [9:00:43<4:17:22,  2.05s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  59%|█████▉    | 10650/18032 [9:08:12<4:43:06,  2.30s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  60%|█████▉    | 10800/18032 [9:15:29<4:46:40,  2.38s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  61%|██████    | 10950/18032 [9:22:44<4:08:45,  2.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  62%|██████▏   | 11100/18032 [9:29:50<8:00:54,  4.16s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  62%|██████▏   | 11250/18032 [9:37:05<4:31:03,  2.40s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  63%|██████▎   | 11400/18032 [9:44:42<4:53:18,  2.65s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  64%|██████▍   | 11550/18032 [9:51:37<4:22:46,  2.43s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  65%|██████▍   | 11700/18032 [9:59:14<3:54:28,  2.22s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  66%|██████▌   | 11850/18032 [10:06:13<4:48:37,  2.80s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  67%|██████▋   | 12000/18032 [10:12:55<3:50:26,  2.29s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  67%|██████▋   | 12150/18032 [10:19:58<3:30:12,  2.14s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  68%|██████▊   | 12300/18032 [10:26:24<3:34:52,  2.25s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  69%|██████▉   | 12450/18032 [10:33:00<3:50:01,  2.47s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  70%|██████▉   | 12600/18032 [10:41:10<3:20:01,  2.21s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  71%|███████   | 12750/18032 [10:49:06<3:47:15,  2.58s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  72%|███████▏  | 12900/18032 [10:56:40<4:00:27,  2.81s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  72%|███████▏  | 13050/18032 [11:03:46<3:24:05,  2.46s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  73%|███████▎  | 13200/18032 [11:10:46<2:26:56,  1.82s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  74%|███████▍  | 13350/18032 [11:18:50<3:14:46,  2.50s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  75%|███████▍  | 13500/18032 [11:26:54<3:20:08,  2.65s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  76%|███████▌  | 13650/18032 [11:34:46<2:47:28,  2.29s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  77%|███████▋  | 13800/18032 [11:42:41<2:48:12,  2.38s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  77%|███████▋  | 13950/18032 [11:49:47<3:55:19,  3.46s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  78%|███████▊  | 14100/18032 [11:57:26<2:45:39,  2.53s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  79%|███████▉  | 14250/18032 [12:05:09<2:32:55,  2.43s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  80%|███████▉  | 14400/18032 [12:12:35<3:14:06,  3.21s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  81%|████████  | 14550/18032 [12:20:26<2:34:12,  2.66s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  82%|████████▏ | 14700/18032 [12:28:49<3:09:07,  3.41s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  82%|████████▏ | 14850/18032 [12:36:40<2:42:23,  3.06s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  83%|████████▎ | 15000/18032 [12:44:33<1:44:58,  2.08s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  84%|████████▍ | 15150/18032 [12:53:07<2:59:12,  3.73s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  85%|████████▍ | 15300/18032 [13:00:36<1:49:49,  2.41s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  86%|████████▌ | 15450/18032 [13:08:15<1:38:39,  2.29s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  87%|████████▋ | 15600/18032 [13:26:34<6:29:27,  9.61s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  87%|████████▋ | 15750/18032 [13:48:07<4:59:06,  7.86s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  88%|████████▊ | 15900/18032 [14:09:42<5:05:19,  8.59s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  89%|████████▉ | 16050/18032 [14:31:26<5:40:21, 10.30s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  90%|████████▉ | 16200/18032 [14:52:57<4:34:52,  9.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  91%|█████████ | 16350/18032 [15:14:34<4:25:21,  9.47s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  91%|█████████ | 16406/18032 [15:22:30<3:06:28,  6.88s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para fornecer uma avaliação adequada, preciso que você forneça a \"Resposta do Modelo\" que deseja que eu avalie em comparação com a \"Resposta Base\". Por favor, compartilhe essa informação para que eu possa proceder com a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|█████████▏| 16500/18032 [15:36:10<4:02:55,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|█████████▏| 16505/18032 [15:37:21<3:13:11,  7.59s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para fornecer uma avaliação precisa, preciso que você me forneça a \"Resposta do Modelo\" que deseja que eu avalie em comparação com a \"Resposta Base\". Por favor, compartilhe essa informação para que eu possa proceder com a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|█████████▏| 16540/18032 [15:41:52<3:27:05,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para fornecer uma avaliação adequada, preciso que você me forneça a \"Resposta do Modelo\" que deseja que eu avalie em comparação com a \"Resposta Base\". Por favor, compartilhe essa informação para que eu possa proceder com a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|█████████▏| 16635/18032 [15:55:33<3:27:47,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para realizar a avaliação, precisamos de uma resposta do modelo para comparar com a resposta base. Como você não forneceu uma resposta do modelo, não posso atribuir notas. Por favor, forneça a resposta do modelo para que eu possa realizar a avaliação conforme solicitado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|█████████▏| 16650/18032 [15:57:45<3:35:48,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|█████████▏| 16665/18032 [15:59:51<2:46:12,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para fornecer uma avaliação adequada, preciso que você me forneça a \"Resposta do Modelo\" que deseja que eu avalie em comparação com a \"Resposta Base\". Por favor, compartilhe essa informação para que eu possa proceder com a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|█████████▏| 16666/18032 [16:00:02<3:10:14,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para fornecer uma avaliação adequada, preciso que você forneça a \"Resposta do Modelo\" que deseja que eu avalie em comparação com a \"Resposta Base\". Por favor, compartilhe essa informação para que eu possa proceder com a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|█████████▏| 16667/18032 [16:00:12<3:21:00,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para fornecer uma avaliação adequada, preciso que você me forneça a \"Resposta do Modelo\" que deseja que eu avalie em comparação com a \"Resposta Base\". Por favor, compartilhe essa informação para que eu possa proceder com a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|█████████▏| 16668/18032 [16:00:22<3:34:54,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para fornecer uma avaliação adequada, preciso que você me forneça a \"Resposta do Modelo\" que deseja que eu avalie em comparação com a \"Resposta Base\". Por favor, compartilhe essa informação para que eu possa proceder com a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|█████████▏| 16669/18032 [16:00:24<2:38:42,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para fornecer uma avaliação adequada, preciso que você me forneça a \"Resposta do Modelo\" que deseja que eu avalie em comparação com a \"Resposta Base\". Por favor, compartilhe essa informação para que eu possa proceder com a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  92%|█████████▏| 16671/18032 [16:00:45<3:20:03,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para fornecer uma avaliação adequada, preciso que você me forneça a \"Resposta do Modelo\" que deseja que eu avalie em comparação com a \"Resposta Base\". Por favor, compartilhe essa informação para que eu possa proceder com a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  93%|█████████▎| 16800/18032 [16:19:21<3:03:41,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  94%|█████████▍| 16950/18032 [16:40:54<2:32:29,  8.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  95%|█████████▍| 17100/18032 [17:02:30<2:13:20,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  96%|█████████▌| 17250/18032 [17:24:09<2:01:57,  9.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  96%|█████████▋| 17400/18032 [17:45:42<1:30:46,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  97%|█████████▋| 17550/18032 [18:07:22<1:15:22,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  98%|█████████▊| 17700/18032 [18:28:56<48:38,  8.79s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  98%|█████████▊| 17731/18032 [18:33:18<30:07,  6.01s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para fornecer uma avaliação adequada, preciso que você me forneça a \"Resposta do Modelo\" que deseja que eu avalie em comparação com a \"Resposta Base\". Por favor, compartilhe essa informação para que eu possa prosseguir com a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  99%|█████████▉| 17850/18032 [18:50:27<20:48,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  99%|█████████▉| 17864/18032 [18:52:38<25:49,  9.22s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para avaliar a resposta do modelo em comparação com a resposta base, precisamos considerar os critérios fornecidos. Vamos assumir que a resposta do modelo não foi apresentada, mas que ela deve ser avaliada em relação à descrição correta do produto.\n",
      "\n",
      "### Avaliação\n",
      "\n",
      "- **Qualidade da Resposta**: Se a resposta do modelo for clara e bem estruturada, ela pode receber uma nota alta. Se for confusa ou mal organizada, a nota deve ser baixa.\n",
      "- **Concordância**: A resposta do modelo deve fazer sentido no contexto da descrição do produto. Se ela se desviar do que foi apresentado na resposta base, a nota deve ser reduzida.\n",
      "- **Precisão/Acurácia**: A resposta deve apresentar informações corretas e relevantes. Se houver erros ou informações imprecisas, a nota deve ser penalizada.\n",
      "- **Alucinação**: Se a resposta do modelo contiver informações inventadas ou inconsistentes, isso deve impactar negativamente a nota.\n",
      "\n",
      "### Exemplo de Avaliação\n",
      "\n",
      "Supondo que a resposta do modelo seja uma descrição que não se alinha com a resposta base, mas ainda assim forneça informações sobre vinhos, a avaliação poderia ser a seguinte:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"quality\": 5,\n",
      "  \"agreement\": 4,\n",
      "  \"accuracy\": 3,\n",
      "  \"hallucination\": 2,\n",
      "  \"justification\": \"A resposta do modelo apresenta algumas informações sobre vinhos, mas não se alinha com a descrição correta do produto conforme a Nomenclatura Comum do Mercosul. A estrutura da resposta é razoável, mas a falta de precisão e a presença de informações não verificáveis resultam em uma nota baixa.\"\n",
      "}\n",
      "```\n",
      "\n",
      "### Nota Final\n",
      "\n",
      "A nota final deve refletir a soma das avaliações em cada critério, considerando a penalização por alucinação e imprecisão. Se a resposta do modelo for muito distante da resposta base, a nota geral deve ser ajustada para refletir isso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  99%|█████████▉| 17865/18032 [18:52:45<24:08,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para avaliar a resposta do modelo em comparação com a resposta base, precisamos considerar os critérios fornecidos. Vamos assumir que a resposta do modelo é uma tentativa de descrever o produto mencionado, mas não temos o texto exato da resposta do modelo. Portanto, faremos uma avaliação hipotética.\n",
      "\n",
      "Suponha que a resposta do modelo seja a seguinte: \"O ESP PETERLONGO PRESENCE MOSCATEL ROSE 12X660ML é um tipo de vinho espumante feito de uvas frescas, que pode ser enriquecido com álcool.\"\n",
      "\n",
      "Agora, vamos avaliar essa resposta em relação à resposta base.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"quality\": 7,\n",
      "  \"agreement\": 8,\n",
      "  \"accuracy\": 6,\n",
      "  \"hallucination\": 4,\n",
      "  \"justification\": \"A resposta do modelo é clara e concisa, mas não é tão precisa quanto a resposta base. Embora mencione que é um vinho espumante e que é feito de uvas frescas, não aborda a parte sobre mostos de uvas e a exclusão de certos tipos de mostos, o que é crucial para a precisão. A resposta não contém informações inventadas, mas a falta de detalhes específicos penaliza a nota.\"\n",
      "}\n",
      "```\n",
      "\n",
      "Se a resposta do modelo fosse diferente, a avaliação poderia mudar. Por favor, forneça a resposta do modelo para uma avaliação mais precisa.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  99%|█████████▉| 17867/18032 [18:52:58<21:33,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Problematic JSON string: Para fornecer uma avaliação adequada, preciso da resposta do modelo para comparar com a resposta base. Por favor, forneça a resposta do modelo para que eu possa realizar a avaliação.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|█████████▉| 18000/18032 [19:12:03<03:43,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 18032/18032 [19:16:44<00:00,  3.85s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Iterate over each row and make API call\n",
    "output_filename = f\"model scoring.csv\"\n",
    "\n",
    "# Initialize progress bar\n",
    "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing\"):\n",
    "    if index % 150 == 0 and index != 0:\n",
    "        print(\"min. pause...\")\n",
    "        time.sleep(60)\n",
    "    try:\n",
    "        comparison_promt = row['comparison_prompt']\n",
    "        \n",
    "        response = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": comparison_promt}],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        generated_text = response.choices[0].message.content\n",
    "        \n",
    "        # Process the JSON response\n",
    "        metadata_str = generated_text.strip()\n",
    "        if metadata_str.startswith(\"```json\") and metadata_str.endswith(\"```\"):\n",
    "            metadata_str = metadata_str.strip(\"```json\").strip()\n",
    "        \n",
    "        try:\n",
    "            data = json.loads(metadata_str)\n",
    "            # Update DataFrame with the extracted values\n",
    "            df.loc[index, 'quality'] = data.get('quality')\n",
    "            df.loc[index, 'agreement'] = data.get('agreement')\n",
    "            df.loc[index, 'accuracy'] = data.get('accuracy')\n",
    "            df.loc[index, 'hallucination'] = data.get('hallucination')\n",
    "            df.loc[index, 'justification'] = data.get('justification')\n",
    "        \n",
    "        except json.JSONDecodeError as e:\n",
    "            # Print error message if JSON decoding fails\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "            print(f\"Problematic JSON string: {metadata_str}\")\n",
    "            df.loc[index, 'quality'] = None\n",
    "            df.loc[index, 'agreement'] = None\n",
    "            df.loc[index, 'accuracy'] = None\n",
    "            df.loc[index, 'hallucination'] = None\n",
    "            df.loc[index, 'justification'] = f\"JSON Error: {e}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        # Print error message if there's an issue processing the line\n",
    "        print(f\"Error processing line {index}: {e}\")\n",
    "        df.loc[index, 'quality'] = None\n",
    "        df.loc[index, 'agreement'] = None\n",
    "        df.loc[index, 'accuracy'] = None\n",
    "        df.loc[index, 'hallucination'] = None\n",
    "        df.loc[index, 'justification'] = f\"Error: {e}\"\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv(output_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
